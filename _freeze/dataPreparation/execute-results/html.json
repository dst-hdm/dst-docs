{
  "hash": "b19364af016c71fa61d9d40b050adb9e",
  "result": {
    "markdown": "# Preparation\n\nWir haben unsere beiden Datensätze unterschiedlich aufbereitet und einen Betrachtungszeitraum von 1920 bis 2013 gewählt. \nGrund dafür war der Naturkatastrophen Datensatz, der sich auf diesen Zeitraum bezieht. Im Folgenden wird die Aufbereitung genauer erläutert.\n\n## Dataprepartion Naturaldisaster\n\n- Nach einer kurzen explorativen Datenanalyse, in der wir die Spalten und NaN-Werte betrachteten, starteten wir direkt mit der Datenvorbereitung für den Datensatz zu Naturkatastrophen.\n- Um wenig aussagekräftige Spalten zu entfernen, schrieben wir ein Skript, welches die Spalten auf die Häufigkeit von NaN\n    Werten prüft und den Prozentsatz der Häufigkeit zurück gibt. Passend dazu erstellten wir ein zweites Skript, welches die Spalten\n    entfernt, die mit ihrer prozentualen NaN Häufigkeit unter einem bestimmten Threashold liegen.\n- Folgende Spalten wurde daraufhin entfernt: \"External IDs\", \"Event Name\", \"OFDA Response\", \"Declaration\", \"AID Contribution ('000 US$)\", \"Magnitude\", \"Magnitude Scale\", \"River Basin\", \"Admin Units\", \"Entry Date\", \"Last Update\". Diese Spalten waren entweder für unsere Visualisierung nicht relevant oder enthielten zu viele NaN-Werte, was ihre Aussagekraft beeinträchtigt hätte.\n- Anschließend erfolgte die Umwandlung der Datentypen, wobei entsprechender Python-Code verwendet wurde.\n- Dann wurden die Daten nach \"Country\", \"Disaster Type\", \"Start Year\", \"ISO\" gruppiert und anschließend ihre Häufigkeit pro Jahr \n    in einer neuen Spalte \"Frequency\" abgebildet.\n- Damit der Datensatz zeitlich vollständig ist, wurden Jahre, in denen keine Katastrophe in einem Land registriert wurde, mit eine \"Frequency\" von \n    `0` ergänzt. Das war vorallem für die Darstellung der Häufigkeit im zeitlichen Verlauf wichtig.\n- Um die Daten später auch auf einer Weltkarte darstellen zu können, wurden sie noch mit Geo-Daten angereichert.    \n    - Koordinatendaten je Land ('latitude', 'longitude') von einem umgewandelten JSON-Objekt welches über den ISO Code des Landes der Daten zugeordnet wurde.\n    - Der nummerisch (`numeric`) Code des Landes nach dem ISO 4217 Standard. Dies war wichtig um die Daten später mit dem von Altair bereitgestellten `contries` Datensatz\n    zu mappen. Der `contries` Datensatz lieferte die Weltkarte als Vektor.\n- Abschließend wurde der DataFrame als CSV-Datei gespeichert.\n\nDie NaN Werte in den Spalten \"ISO\", \"latitude\", \"longitude\", \"numeric\" kommen nur bei einer \"Frequency\" von `0` auf und daher nicht relevant für die spätere Darstellung. \n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Disaster Type</th>\n      <th>Start Year</th>\n      <th>ISO</th>\n      <th>Frequency</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>numeric</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>India</td>\n      <td>Epidemic</td>\n      <td>1920</td>\n      <td>IND</td>\n      <td>2.0</td>\n      <td>20.0</td>\n      <td>77.0</td>\n      <td>356.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>India</td>\n      <td>Epidemic</td>\n      <td>1921</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>India</td>\n      <td>Epidemic</td>\n      <td>1922</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>India</td>\n      <td>Epidemic</td>\n      <td>1923</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>India</td>\n      <td>Epidemic</td>\n      <td>1924</td>\n      <td>IND</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>77.0</td>\n      <td>356.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Data Preparation für Temperatur\nZu Beginn der Datenvorbereitung für den Datensatz wurde jedem Land eine eindeutige UID-Zelle zugewiesen und diese wurde befüllt.\nAnschließend wurde die Datenstruktur durch das Betrachten von Head und Tail überprüft, woraufhin die verbleibenden NaN-Werte entfernt wurden.\nDanach wurden die Datentypen betrachtet und angepasst. Hierbei erfolgte eine Änderung des Datetime-Formats und der Datentyp der Spalte \"Country\" wurde zu \"Category\" geändert.\nAnschließend wurde der DataFrame nach der Jahreszahl gefiltert und alle UID-Werte (nach ISO 4217 Standard), die als \"Unknown\" gekennzeichnet waren, wurden entfernt.\nNach dieser Aktion erfolgte die Verknüpfung mit den ISO-Ländercodes, wobei entsprechender Python-Code verwendet wurde.\nAnschließend wurden die Ländernamen an die Ländernamen des Datensatzes zu Naturkatastrophen angepasst.\nZum Abschluss wurde eine CSV-Datei erstellt.\nDie verwendeten Bibliotheken waren Pandas und pycountry.\n\n::: {.cell execution_count=2}\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dt</th>\n      <th>AverageTemperature</th>\n      <th>AverageTemperatureUncertainty</th>\n      <th>uid</th>\n      <th>ISO</th>\n      <th>Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1920-01-01</td>\n      <td>1.385</td>\n      <td>0.589</td>\n      <td>4</td>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1920-02-01</td>\n      <td>0.689</td>\n      <td>0.742</td>\n      <td>4</td>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1920-03-01</td>\n      <td>7.944</td>\n      <td>0.953</td>\n      <td>4</td>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1920-04-01</td>\n      <td>11.725</td>\n      <td>0.849</td>\n      <td>4</td>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1920-05-01</td>\n      <td>17.695</td>\n      <td>0.662</td>\n      <td>4</td>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n",
    "supporting": [
      "dataPreparation_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}